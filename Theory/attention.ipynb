{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1f9bdf-22f8-4623-b6be-52479c04f5a9",
   "metadata": {},
   "source": [
    "Attention = \"communication\" phase\n",
    "- soft, data-dependent message passing on directed graphs\n",
    "- each node stores a vector\n",
    "- there is a (1) \"communication phase\"\n",
    "- and then (2) \"compute phase\"\n",
    "\n",
    "\n",
    "Each node has data vector (Think of it as private information to this node.)\n",
    "The node can also emit:\n",
    "1. Key: what do I have\n",
    "2. Query: what am I looking for\n",
    "3. Value: what do I publicly reveal/broadcast to others\n",
    "The key query and value are emitted by a simple **linear transformation**.\n",
    "\n",
    "\n",
    "So let's say we loop over all the nodes in this graph in some random order, and you're at some node. \n",
    "1. We get the **query** vector q. Which is, what is this node looking for? (\"I'm a node in some graph, and this is what I'm looking for.\"). And this is just achieved via a linear transformation.\n",
    "2. We look at al the inputs that point to this node. And then they broadcast, \"What are the things that I have?\", their **keys**\n",
    "3. The query and the keys interact via dot products, to get **scores**. By simply doing a dot product, you get an unnormalized weighting of the \"interestingness\" of all the information in the nodes that points to me, and to the things I'm looking for.\n",
    "4. When we normalize everything with Softmax, which now sum to 1 and are a probability distribution.\n",
    "5. We do a weighted sum of the values. This weighted sums flow to me and update me (as the orginal node)\n",
    "6. This happens for each node individually.\n",
    "\n",
    "### Cross Attention\n",
    "\n",
    "Self-attention and cross attention only differ where the **keys** and the **values** come from.\n",
    "\n",
    "\n",
    "\n",
    "**Self- attention (in both encoder and decoder)**:\n",
    "- each token attends to other tokens in its own sequence\n",
    "\n",
    "**Cross attention** (only in decoder):\n",
    "- Queries: come from decoder's current state\n",
    "- Keys/Values: come from encoder's output (h_1, h_n)\n",
    "In cross-attention lets the decoder's queries search through encoders's processed information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f186ede6-1491-42fa-8663-e35fe0a8cbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.99979163e-01,  4.58765984e-01, -4.17972421e-01,  1.54274927e+00,\n",
       "        1.83273755e+00, -2.59791488e-01, -1.48971258e-01,  5.09773723e-01,\n",
       "        4.93034858e-01, -7.57942453e-01,  1.00258714e+00, -7.64363985e-01,\n",
       "       -4.99916556e-01, -2.60030829e+00, -1.38047930e+00,  3.82105985e-01,\n",
       "        1.67284723e+00, -1.84113331e+00, -1.60141138e+00, -7.60866686e-04])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.randn(20)\n",
    "wkey = np.random.randn(20,20)\n",
    "wquery = np.random.randn(20,20)\n",
    "wvalue = np.random.randn(20,20)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7006d36e-49e8-4bdd-9153-904b3cb308e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -6.27525465,   0.53520223,  -4.41777674,   6.05004757,\n",
       "        -3.71431048,   0.98031709, -10.86560105,  -1.74342024,\n",
       "        -1.83454916,  -1.22479811,   1.81280736,  -4.09964583,\n",
       "        -9.68843426,  -3.19294063,  -1.14339306,   8.48523855,\n",
       "        -4.43880752,  -7.62228925,   7.53366388,  -2.03175661])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key: what do I have\n",
    "wkey @ x\n",
    "\n",
    "# query: what am I looking for\n",
    "wquery @ x\n",
    "\n",
    "\n",
    "# value: what do I publicly reveal/broadcast to other\n",
    "wvalue @ x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f5faa0-1615-484a-9d40-430ba67f2c2e",
   "metadata": {},
   "source": [
    "Intutions for KQV:\n",
    "- Keys and Queries exist to compute relevance (via similarity scores)\n",
    "- Values exist to provide content once relevance is determined\n",
    "\n",
    "\n",
    "1. Each token's representation is a weighted sum of all the tokens in the context.\n",
    "2. Applies multiple layers of self-attention, where each token attends to all other tokens\n",
    "3. Outputs transfromerd embeddngs that capture contextual relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa334939-c859-4622-82c3-f21b9f701384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
