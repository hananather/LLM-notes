{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32dd52a0-643e-45cf-bd39-409d90787b5e",
   "metadata": {},
   "source": [
    "**Function calling** enables us to connect LLMs to external data and systems. \n",
    "We can define a set of functions as tools that the model has access to, and it can use them when appropriate based on the conversation history. We can then execute those functions on the **application** side, and provide the results back to the model. \n",
    "\n",
    "\"Function calling\" naming is confusing. LLMs don't actually call any functions themselves; they suggest which functions you should call from  pre-defined functions which you provide to the LLM in a prompt. Function calling is a type of structured ouput capability of a LLM. Yet, strctured output enables us to intergate LLMs with classical software systems.\n",
    "\n",
    "When you use function calling, the model never actually executes functions itself, instead it simply generates parameters that can be used to call our function. \n",
    "\n",
    "#### Warning\n",
    "Before diving any deeper, remember, all an LLM does it next token prediction. Due to the principle LLM architecture all it can possibly output is one token with the highes probability. In documentation OpenAI refers to function calling as a capability. Function calling capability is achieved via fine-tuning of a model, when enables it to output data in a specific way. To oversimplify, a structured-output-capable model was just trained on more JSON. Therefore, function calling is merely JSON structured output which contains the name of a function to call and parameters for it.\n",
    "\n",
    "#### Why do we care about function calling?\n",
    "Three main reasons:\n",
    "1. **Models don't have all the data**. Models acquire their \"knowledge\" during the training process, and that \"knowlege\" is stored in the model's weights, we cannot be easily updated on demand. To update \"knowlege\" you effectively need to update the model's weights and run all the post-training routines.\n",
    "\n",
    "2. **Models need to be integrated with other systems**. Strcutured output capability enables output to be integrated with other parts of the system via JSON. We can even treat strctured output-enabled LLM as some sort of API which returns JSON. There is a world of difference between: \n",
    "\n",
    "```\n",
    "Hi, my name is Hanan Ather, I'm 27, and my email is hanan@example.com\n",
    "\n",
    "```\n",
    "and \n",
    "```\n",
    "{\n",
    "    \"name\": \"Hanan Ather\",\n",
    "    \"age\": 27,\n",
    "    \"email\": \"hanan@example.com\"\n",
    "}\n",
    "\n",
    "```\n",
    "Strcutured output not only make integrations simpler, but they easily enable tasks which normally required eloborated NLP systems. \n",
    "\n",
    "\n",
    "Many applications require models to call custom functions to trigger actions within the application or interact with external systems.\n",
    "\n",
    "- Fetching data: enable a conversational assistant to retrieve databased on conversation, like scheduling meetings or initiating order systems\n",
    "- Taking action: allowing a assistant to trigger actions based on the conversation, like scheduling meetings or initiating order returns\n",
    "- Building workflows: allow assistants to execute multi-step workflows, like data extraction pipelines or content personalization\n",
    "\n",
    "### How Strcutured Output Works\n",
    "Strcutured output is a models capability to output JSON, acquired during fine-tuning. \n",
    "\n",
    "**Use case of strcutured output:**\n",
    "- implement a natural langugage processing parser that allows users to create grocery lists out of natural langauge input. The use provides a list of groceries in written or spoken form, and the program outputs an HTML-formatted list.\n",
    "\n",
    "  - Without LLMs, this is not such an easy task to tackle. Its easy to build a demo, but not easy to build-high quality prodcut that handles edge cases well. \n",
    "\n",
    "- Today we can accomplish this by: pipe user input into the LLM -> LLM outputs JSON -> Python picks it up and formats the JSON into HTML\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29a1dfe-a05f-4494-a73a-55605b0317d6",
   "metadata": {},
   "source": [
    "Here is how we can define a function as a tool for the model to use: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb6d882-52fb-4cdd-851d-40f4159da7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "  {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "          \"name\": \"get_weather\",\n",
    "          \"parameters\": {\n",
    "              \"type\": \"object\",\n",
    "              \"properties\": {\n",
    "                  \"location\": {\"type\": \"string\"}\n",
    "              },\n",
    "          },\n",
    "      },\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347e4277-563f-4ed4-90e4-0691c466968f",
   "metadata": {},
   "source": [
    "The starting point for function calling is choosing a function in your own codebase that you'd like to enable the model to generate arguments for. \n",
    "\n",
    "### Handling model responses\n",
    "The model only suggests function calls and generates arguments for the defined functions when appropriate. It is then up to us to decide how our application handles the execution of these suggestions. \n",
    "\n",
    "If the model determines that a function should be called, it will return a `tool_calls` field in the response, which we can use to determine if the model generated a function call and what the argumets were."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
