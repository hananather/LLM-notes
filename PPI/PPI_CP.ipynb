{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fa4f604",
   "metadata": {},
   "source": [
    "# Prediction-Powered Inference (PPI)\n",
    "\n",
    "## Introduction and Problem Setup\n",
    "\n",
    "**Prediction-Powered Inference (PPI)** is a statistical framework that enables valid inference when we have:\n",
    "- A large dataset of **unlabeled covariates** $\\{X_i\\}_{i=1}^N$ (size $N$, typically very large)\n",
    "- A small dataset of **labeled observations** $\\{(X_i, Y_i)\\}_{i=1}^n$ (size $n \\ll N$)\n",
    "- A predictive model $f: \\mathcal{X} \\to \\mathcal{Y}$ trained on labeled data\n",
    "\n",
    "### The Core Challenge\n",
    "\n",
    "Given these resources, we want to estimate some population parameter $\\theta^* = \\mathbb{E}[g(Y, X)]$ where $g$ is a known function. Examples include:\n",
    "- **Mean estimation**: $\\theta^* = \\mathbb{E}[Y]$ where $g(y,x) = y$\n",
    "- **Regression coefficients**: $\\theta^* = \\mathbb{E}[XY]$ for linear regression\n",
    "- **Risk measures**: $\\theta^* = \\mathbb{E}[\\mathbf{1}\\{Y > t\\}]$ for threshold exceedance\n",
    "\n",
    "### Why Not Just Use ML Predictions?\n",
    "\n",
    "The naive approach would be to:\n",
    "1. Train $f$ on labeled data\n",
    "2. Predict $\\hat{Y}_i = f(X_i)$ for all unlabeled $X_i$\n",
    "3. Estimate $\\tilde{\\theta}_f = \\frac{1}{N}\\sum_{i=1}^N g(\\hat{Y}_i, X_i)$\n",
    "\n",
    "**This fails because:**\n",
    "$$\\mathbb{E}[\\tilde{\\theta}_f] = \\mathbb{E}[g(f(X), X)] \\neq \\mathbb{E}[g(Y, X)] = \\theta^*$$\n",
    "\n",
    "The estimator $\\tilde{\\theta}_f$ is **biased** unless $f(X) = Y$ almost surely (perfect prediction).\n",
    "\n",
    "## Mathematical Framework\n",
    "\n",
    "### The Rectifier Approach\n",
    "\n",
    "PPI introduces a **rectifier** $\\Delta$ that captures the systematic bias:\n",
    "$$\\Delta = \\mathbb{E}[g(Y, X) - g(f(X), X)]$$\n",
    "\n",
    "The key insight is that $\\theta^*$ can be decomposed as:\n",
    "$$\\theta^* = \\mathbb{E}[g(f(X), X)] + \\Delta = \\tilde{\\theta}_f^{pop} + \\Delta$$\n",
    "\n",
    "where $\\tilde{\\theta}_f^{pop} = \\mathbb{E}[g(f(X), X)]$ is the population version of our biased estimator.\n",
    "\n",
    "### PPI Estimator Construction\n",
    "\n",
    "**Step 1: Estimate the bias using labeled data**\n",
    "$$\\hat{\\Delta} = \\frac{1}{n}\\sum_{i=1}^n [g(Y_i, X_i) - g(f(X_i), X_i)]$$\n",
    "\n",
    "**Step 2: Estimate population predictions using unlabeled data**\n",
    "$$\\tilde{\\theta}_f = \\frac{1}{N}\\sum_{i=1}^N g(f(X_i), X_i)$$\n",
    "\n",
    "**Step 3: Construct the PPI estimator**\n",
    "$$\\hat{\\theta}_{PPI} = \\tilde{\\theta}_f + \\hat{\\Delta}$$\n",
    "\n",
    "### Theoretical Properties\n",
    "\n",
    "**Unbiasedness**: \n",
    "$$\\mathbb{E}[\\hat{\\theta}_{PPI}] = \\mathbb{E}[\\tilde{\\theta}_f] + \\mathbb{E}[\\hat{\\Delta}] = \\tilde{\\theta}_f^{pop} + \\Delta = \\theta^*$$\n",
    "\n",
    "**Variance**: Under independence assumptions,\n",
    "$$\\text{Var}(\\hat{\\theta}_{PPI}) = \\text{Var}(\\tilde{\\theta}_f) + \\text{Var}(\\hat{\\Delta}) = \\frac{\\sigma_f^2}{N} + \\frac{\\sigma_{\\Delta}^2}{n}$$\n",
    "\n",
    "where:\n",
    "- $\\sigma_f^2 = \\text{Var}(g(f(X), X))$\n",
    "- $\\sigma_{\\Delta}^2 = \\text{Var}(g(Y, X) - g(f(X), X))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d070f8",
   "metadata": {},
   "source": [
    "## Confidence Intervals and Inference\n",
    "\n",
    "### Asymptotic Distribution\n",
    "\n",
    "Under regularity conditions, as $n, N \\to \\infty$ with $n/N \\to \\lambda \\in [0,1]$:\n",
    "\n",
    "$$\\sqrt{n}(\\hat{\\theta}_{PPI} - \\theta^*) \\xrightarrow{d} \\mathcal{N}(0, \\sigma_{PPI}^2)$$\n",
    "\n",
    "where the asymptotic variance is:\n",
    "$$\\sigma_{PPI}^2 = \\frac{n}{N}\\sigma_f^2 + \\sigma_{\\Delta}^2$$\n",
    "\n",
    "### Confidence Interval Construction\n",
    "\n",
    "The **rectifier set approach** constructs confidence intervals by accounting for uncertainty in $\\hat{\\Delta}$:\n",
    "\n",
    "**Step 1**: Build a confidence set for $\\Delta$\n",
    "$$R_{\\alpha} = \\left[\\hat{\\Delta} - z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{\\sigma}_{\\Delta}^2}{n}}, \\hat{\\Delta} + z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{\\sigma}_{\\Delta}^2}{n}}\\right]$$\n",
    "\n",
    "where $\\hat{\\sigma}_{\\Delta}^2 = \\frac{1}{n-1}\\sum_{i=1}^n (g(Y_i, X_i) - g(f(X_i), X_i) - \\hat{\\Delta})^2$\n",
    "\n",
    "**Step 2**: Construct the prediction-powered confidence set\n",
    "$$C_{PPI} = \\{\\tilde{\\theta}_f + \\delta : \\delta \\in R_{\\alpha}\\}$$\n",
    "\n",
    "This gives the $(1-\\alpha)$-level confidence interval:\n",
    "$$\\left[\\tilde{\\theta}_f + \\hat{\\Delta} - z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{\\sigma}_{\\Delta}^2}{n}}, \\tilde{\\theta}_f + \\hat{\\Delta} + z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{\\sigma}_{\\Delta}^2}{n}}\\right]$$\n",
    "\n",
    "### Efficiency Gains\n",
    "\n",
    "The **efficiency gain** of PPI over classical inference depends on the prediction quality. Define the **correlation coefficient**:\n",
    "$$\\rho = \\frac{\\text{Cov}(g(Y,X), g(f(X),X))}{\\sqrt{\\text{Var}(g(Y,X))\\text{Var}(g(f(X),X))}}$$\n",
    "\n",
    "The **relative efficiency** of PPI vs. classical estimator is approximately:\n",
    "$$\\text{RE} \\approx \\frac{1 + \\lambda(1-\\rho^2)}{1-\\rho^2}$$\n",
    "\n",
    "where $\\lambda = n/N$. As $\\rho \\to 1$ (perfect predictions), $\\text{RE} \\to \\infty$, meaning enormous efficiency gains.\n",
    "\n",
    "### Key Mathematical Insights\n",
    "\n",
    "1. **Bias-Variance Tradeoff**: PPI trades off between:\n",
    "   - **Variance reduction** from using large $N$ unlabeled samples\n",
    "   - **Bias correction** using small $n$ labeled samples\n",
    "\n",
    "2. **Optimality**: When $f$ has good predictive power ($\\rho$ close to 1), PPI can achieve the efficiency of having $N$ labeled samples while only requiring $n$ labels.\n",
    "\n",
    "3. **Robustness**: PPI validity requires no assumptions on $f$ beyond measurability - it works with any black-box predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5063e",
   "metadata": {},
   "source": [
    "## PPI Workflow Visualization\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    %% Input Data\n",
    "    subgraph \"Input Data\"\n",
    "        A[\"`**Large Unlabeled Data**\n",
    "        X₁, X₂, ..., X_N\n",
    "        Size: N (very large)`\"]\n",
    "        B[\"`**Small Labeled Data** \n",
    "        (X₁,Y₁), (X₂,Y₂), ..., (X_n,Y_n)\n",
    "        Size: n << N`\"]\n",
    "    end\n",
    "    \n",
    "    %% Model Training\n",
    "    subgraph \"Model Training\"\n",
    "        C[\"`**Train Predictor**\n",
    "        f: X → Y\n",
    "        using labeled data`\"]\n",
    "    end\n",
    "    \n",
    "    %% Two Parallel Computations\n",
    "    subgraph \"Parallel Computations\"\n",
    "        D[\"`**Unlabeled Path**\n",
    "        Compute predictions f(Xᵢ)\n",
    "        for all N unlabeled points`\"]\n",
    "        E[\"`**Labeled Path**\n",
    "        Compute predictions f(Xᵢ) \n",
    "        for all n labeled points`\"]\n",
    "    end\n",
    "    \n",
    "    %% Core PPI Components\n",
    "    subgraph \"PPI Components\"\n",
    "        F[\"`**Biased Estimator**\n",
    "        θ̃_f = (1/N) Σ g(f(Xᵢ), Xᵢ)\n",
    "        Uses all N predictions`\"]\n",
    "        G[\"`**Rectifier (Bias Correction)**\n",
    "        Δ̂ = (1/n) Σ [g(Yᵢ,Xᵢ) - g(f(Xᵢ),Xᵢ)]\n",
    "        Estimates systematic bias`\"]\n",
    "        H[\"`**Variance Estimation**\n",
    "        σ̂²_Δ = Var[g(Y,X) - g(f(X),X)]\n",
    "        For confidence intervals`\"]\n",
    "    end\n",
    "    \n",
    "    %% Final Results\n",
    "    subgraph \"Final Inference\"\n",
    "        I[\"`**PPI Estimator**\n",
    "        θ̂_PPI = θ̃_f + Δ̂\n",
    "        Unbiased estimate`\"]\n",
    "        J[\"`**Confidence Interval**\n",
    "        θ̂_PPI ± z₁₋α/₂ √(σ̂²_Δ/n)\n",
    "        Valid statistical inference`\"]\n",
    "    end\n",
    "    \n",
    "    %% Flow connections\n",
    "    A --> C\n",
    "    B --> C\n",
    "    C --> D\n",
    "    C --> E\n",
    "    \n",
    "    D --> F\n",
    "    E --> G\n",
    "    B --> H\n",
    "    \n",
    "    F --> I\n",
    "    G --> I\n",
    "    H --> J\n",
    "    I --> J\n",
    "    \n",
    "    %% Styling\n",
    "    classDef inputStyle fill:#e3f2fd,stroke:#1976d2,stroke-width:2px\n",
    "    classDef modelStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px\n",
    "    classDef computeStyle fill:#e8f5e8,stroke:#388e3c,stroke-width:2px\n",
    "    classDef ppiStyle fill:#fff3e0,stroke:#f57c00,stroke-width:2px\n",
    "    classDef resultStyle fill:#fce4ec,stroke:#c2185b,stroke-width:2px\n",
    "    \n",
    "    class A,B inputStyle\n",
    "    class C modelStyle\n",
    "    class D,E computeStyle\n",
    "    class F,G,H ppiStyle\n",
    "    class I,J resultStyle\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4513d6-12d5-4085-a6d9-2ad368060626",
   "metadata": {},
   "source": [
    "**What estimands can PPI be used for?**\n",
    "The principe of prediction powered inference can be used for constructing valid CI for any estimand that can be expressed as a minimizer of a convex objective function. \n",
    "\n",
    "---\n",
    "\n",
    "**Prediction-Powered Inference For LLM Eval**\n",
    "\n",
    "We have two signals for assessing model performance: \n",
    "- human labels which are typically accurate, but expensive to collect. Usually only a small sample size is available. An estimate based on these samples alone will have high variance.\n",
    "\n",
    "- **autorater predictions.** Are easy to collect for large sample sizes, but may also be systematically biased.\n",
    "\n",
    "This suggest that one must make a choice between either (1) a high-variance, but unbiased, estimate from a small human sample or (2) a lower-variance but biased, autorater-based estimate.\n",
    "\n",
    "**PPI gives us a statistically valid way of combining the auto-rater and human data for hybrid evaluations.**\n",
    "\n",
    "\n",
    "Standard PPI does not take heterogeneity into account.\n",
    "\n",
    ">  Heterogeneity refers to dissimilarities or variations across different subgroups or conditions within your data. This implies that a single, simple model or a single set of parameters might not adequately describe the entire population or dataset. The underlying processes, relationships, or effects differ for distinct parts of the data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c24ffd-bc36-46f0-aee4-aa05c41b5124",
   "metadata": {},
   "source": [
    "**Core Idea:**\n",
    "- You have a large set of unlabeled covariates X, but only a small sample of observed outcomes Y\n",
    "- Train a predictive model $f(X)$ on labeled data, then use it to estimate a parameter (e.g., mean, proportion) over the entire population using unlabeled data.\n",
    "- Valid inference is achieved by _correcting_ the bias of the predictor via a labeled test set.\n",
    "\n",
    "Prediction Powered inference allows us to \"impute\" outcomes via ML to boost effective sample size, then use those labeled data to \"rectify\" those imputations so that all the resulting \n",
    "\n",
    "**Why can’t we simply plug in ML-imputed labels into a standard confidence‐interval procedure and be done?**\n",
    "1. **Bias & Invalid Coverage**: When you replace the true $Y_i$ with $f(X_i)$, your estimator $\\tilde\\theta_f$ will typically be **biased** (unless f is perfect), and as a result your CI will **under- or over-cover** the true parameter $\\theta^*$\n",
    "2. Prediction-Powered Inference (PPI) fixes this by introducing a **rectifier** $\\Delta$ that captures the systematic error from using $f(X)$ in place of Y.  Concretely, for the simple case of estimating a mean, one defines$$\n",
    "    \\Delta ;=; \\mathbb{E}\\bigl[Y - f(X)\\bigr],$$and then uses the labeled data to build a **confidence set** $R$ for $\\Delta$.  Finally, one **“rectifies”** the naive estimator $\\tilde\\theta_f$ by each candidate in $R$ to obtain a valid CI for $\\theta^*$\n",
    " Only **after** you ensure **validity** via the rectifier, without it, you’d simply be averaging biased predictions under the false pretence they’re “real” data.\n",
    "\n",
    "---\n",
    "\n",
    "In prediction-powered inference (PPI), the “rectifier set” $R$ is **not** the single-point estimate $\\hat\\Delta$ but rather a **confidence set** containing all plausible values of the rectifier $\\Delta$ given your labeled data.  Because $\\Delta$ is itself estimated with sampling noise, we construct $R$ (typically an interval) to capture that uncertainty.  In the mean‐estimation warm‐up, $\\Delta = \\mathbb{E}[\\,f(X)-Y\\,]$ is estimated by the empirical average $\\hat\\Delta = \\frac1n\\sum_i\\bigl(f(X_i)-Y_i\\bigr)$; the rectifier set is then\n",
    "$$\n",
    "R = \\bigl[\\hat\\Delta - z_{1-\\delta/2}\\,\\mathrm{SE}(\\hat\\Delta),\\;\\hat\\Delta + z_{1-\\delta/2}\\,\\mathrm{SE}(\\hat\\Delta)\\bigr],\n",
    "$$\n",
    "an **infinite** continuum of values rather than a single number\n",
    "# Conformal Predition\n",
    "**Core Idea:**\n",
    "- CP wraps around _any_ predictive model (black-box or otherwise)\n",
    "- Given a trained model and a calibration set, it outputs _set-valued predictions_ that contain the true label (or value) with probability $≥ 1 − α$.\n",
    "- It gives **finite-sample, distribution-free guarantees**.\n",
    "**Ideas:**\n",
    "**Quality Assurance in Imputation:** Use CP to generate _interval estimates_ when imputing missing values (e.g., in income, education level).\n",
    "**Outlier Detection**: Conformal methods (like Conformal Anomaly Detection) could flag units whose predicted behavior doesn’t match the calibration distribution.\n",
    "\n",
    "- CP works by computing nonconformity scores on previous unlabled data, and using these to create prediction sets on a new (unlabled) test data\n",
    "- requires a user specified significance level for which the algorithm should produce its predictions (predicton sets)\n",
    "    - this significance level restricts the frequency of errors that the algorithm is allowed to make;\n",
    "    - for example, significance of 0.1 means that the algorithm can make at more 10% erroneous predictons \n",
    "- To meet this requirement, the output is a predictions set, instead of a point prediction produced by standard supervised models\n",
    "    - for classification, this means that predictions are not a single class, for example `cat`, but instead, a set `{‘cat’, ‘dog'}`\n",
    "- depending on how good this underlying model is (how well it can discen between classes) and the specified significance level, these sets can be smaller or larger. \n",
    "- for regression tasks, the output is prediction intervals\n",
    " --- \n",
    " C is a _set-valued_ function that maps each test point $X_{\\text{test}}$ to a subset of the K possible labels.  Concretely, after calibration you compute\n",
    "$$C(X_{\\text{test}}) \\;=\\; \\{\\,y\\in\\{1,\\dots,K\\}: \\hat f(X_{\\text{test}})_y \\;\\ge\\;1 - \\hat q\\},$$\n",
    "Let:\n",
    "- $\\hat f(x)_y$ be your model’s softmax “probability” for class $y$.\n",
    "- $\\alpha\\in(0,1)$ be your target miscoverage level (e.g. $\\alpha=0.1$ for 90 % coverage)\n",
    "- A calibration set $\\{(X_i,Y_i)\\}_{i=1}^n$\n",
    "To construct $C$ from $\\hat f$ and the calibration data:\n",
    "1. Nonconformity Scores\n",
    "$$s_i \\;=\\; 1 - \\hat f(X_i)_{Y_i} \\quad\\text{for }i=1,\\dots,n$$\n",
    "A large $s_i$ means the model gave low probability to the true label.  \n",
    "2. **Threshold via empirical quantile.**\n",
    "Order the $s_i’s$ from smallest to largest and let\n",
    "$\\hat q_{1-\\alpha} \\;=\\; \\text{the }\\lceil (n+1)(1-\\alpha)\\rceil\\text{-th smallest }s_i.$\n",
    "Equivalently, $\\hat q_{1-\\alpha}$ is the smallest number such that at least $(1-\\alpha)\\times100\\%$ of the calibration scores satisfy $s_i \\le \\hat q_{1-\\alpha}$.\n",
    "3. **Prediction sets.**\n",
    "For a\n",
    "4. we set the conformal scores si = 1-f(Xi) to be (one minus the softmax output of the true class). The score is high when the model is baldy wrong.\n",
    "5. Define $\\hat q$ to be the empirical quantile \n",
    "6. For a new test data set create a prediction set such that:\n",
    "$$C(X_{\\text{test}}) \\;=\\; \\{\\,y\\in\\{1,\\dots,K\\}: \\hat f(X_{\\text{test}})_y \\;\\ge\\;1 - \\hat q\\},$$\n",
    "\tthat includes all classes with a high enough softmax output. \n",
    "\n",
    "--- \n",
    "## **Cross-Prediction-Powered Inference (CrossPPI)**\n",
    "### **Core Idea**\n",
    "CrossPPI addresses the overfitting and bias that arise when the **same** data are used to train $f$ and to estimate the rectifier.  It partitions the labeled dataset into K folds: for each fold, the model is trained on the other K-1 folds and used to predict on the held-out fold; this “cross-prediction” mimics an independent test set and avoids overly optimistic bias estimates  .\n",
    "### **Debiasing Mechanism**\n",
    "\n",
    "1. **Fold-wise rectifiers** $\\hat\\Delta^{(k)}$ are computed on each held-out fold k.\n",
    "2. These are pooled to form an overall confidence set R for the bias $\\Delta$.\n",
    "3. The final **prediction-powered set**\n",
    "    \n",
    "$$C_{PP} \\;=\\;\\bigl\\{\\;\\tilde\\theta_f + d : d\\in R\\bigr\\}$$\n",
    "    \n",
    "    retains exact coverage while leveraging all labeled data without reuse bias  .\n",
    "CrossPPI requires only that predictions be measurable functions of the training folds—**no consistency** or **i.i.d. guarantees** on f are needed for validity.  Empirically, it often tightens intervals compared to classical PPI when the model generalizes well across folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729fa98d-4bd2-428d-a257-15951ef3aa4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
