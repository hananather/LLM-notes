{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d55ece7c-1b2e-4fb8-bc36-14d1f0e653db",
   "metadata": {},
   "source": [
    "A prompt is an instruction given to a model to perform a task. A prompt generally consists of one or more of the following parts:\n",
    "- Task description: \n",
    "- Examples(s) of how to do this task:\n",
    "- The task:\n",
    "\n",
    "For prompting to work, the model has to be able to follow instructions. If a model is bad at it, it doesn't matter how good your prompt is, the model won't be able to follow it. \n",
    "\n",
    "How much prompt engineering is needed depends on how robust the model is to prompt perturbation.\n",
    "You can measure a model's robustness by randomly perturbing the prompts to see how the output changes. \n",
    "- just like instuction following capability, a model's robustness is strongly correlated with overall capability. As models become stronger, they also become more robust. For this reason, working with stronger models can often save you headaches and reduce time wasted on fiddling.\n",
    "\n",
    "## In-Context Learning: Zero-Shot and Few-Shot Prompting "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
