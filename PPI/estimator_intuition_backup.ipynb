{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (2.2.1)\n",
      "Requirement already satisfied: pandas in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (3.10.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (1.7.0)\n",
      "Requirement already satisfied: seaborn in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (from matplotlib) (4.58.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install numpy pandas matplotlib scikit-learn seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Intuition for Survey Estimators: A Simple Simulation\n",
    "\n",
    "## The Fundamental Insight: \"Predict-and-Correct\"\n",
    "\n",
    "**Every survey estimator follows the same basic formula:**\n",
    "\n",
    "$$\\text{Total Estimate} = \\text{Predicted Total} + \\text{Correction for Prediction Error}$$\n",
    "\n",
    "This notebook demonstrates this core concept using a simple, intuitive example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario: Estimating Total Business Revenue in a Region\n",
    "\n",
    "We'll use a business revenue example with an obvious, intuitive relationship:\n",
    "\n",
    "- **Population**: 1,000 businesses in a region\n",
    "- **Sample**: We survey only 50 businesses (5%)\n",
    "- **Target variable (Y)**: Annual revenue ($)\n",
    "- **Auxiliary variable (X)**: Number of employees (known for all businesses from business registry)\n",
    "- **Intuitive relationship**: More employees → Higher revenue\n",
    "\n",
    "### Why This Example Works Well\n",
    "\n",
    "1. The relationship is obvious: larger businesses (more employees) generate more revenue\n",
    "2. It's realistic: business registries often have employee counts but not revenue\n",
    "3. The numbers are interpretable: ~$50,000 revenue per employee is reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Make plots look better\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create the Population of Businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population parameters\n",
    "N = 1000  # Total number of businesses in the region\n",
    "n = 50    # Number of businesses we'll sample\n",
    "\n",
    "# Generate business data\n",
    "# Number of employees: small businesses (1-5), medium (6-20), large (21-50)\n",
    "employees = np.concatenate([\n",
    "    np.random.randint(1, 6, 600),      # 60% small businesses\n",
    "    np.random.randint(6, 21, 300),     # 30% medium businesses  \n",
    "    np.random.randint(21, 51, 100)     # 10% large businesses\n",
    "])\n",
    "\n",
    "# Revenue relationship: roughly $50,000 per employee + noise\n",
    "# This is intuitive: more employees = more capacity = more revenue\n",
    "base_revenue_per_employee = 50000\n",
    "revenue = base_revenue_per_employee * employees + np.random.normal(0, 20000, N) * employees\n",
    "\n",
    "# Create population dataframe\n",
    "population = pd.DataFrame({\n",
    "    'business_id': range(N),\n",
    "    'employees': employees,\n",
    "    'revenue': revenue\n",
    "})\n",
    "\n",
    "# TRUE TOTAL we want to estimate\n",
    "TRUE_TOTAL = population['revenue'].sum()\n",
    "print(f\"True total revenue for all businesses: ${TRUE_TOTAL:,.0f}\")\n",
    "print(f\"Average revenue per business: ${TRUE_TOTAL/N:,.0f}\")\n",
    "print(f\"\\nPopulation summary:\")\n",
    "print(population.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Take a Random Sample\n",
    "\n",
    "In practice, we can only afford to survey a small fraction of businesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a simple random sample\n",
    "sample_idx = np.random.choice(N, n, replace=False)\n",
    "sample = population.iloc[sample_idx].copy()\n",
    "sample['weight'] = N/n  # Each sampled business represents N/n businesses\n",
    "\n",
    "print(f\"Sample size: {n} businesses ({n/N*100:.0f}% of population)\")\n",
    "print(f\"\\nSample summary:\")\n",
    "print(sample[['employees', 'revenue']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Apply Each Estimator\n",
    "\n",
    "Now we'll see how each estimator uses the same \"predict-and-correct\" logic with different approaches to prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Difference Estimator\n",
    "\n",
    "**Key assumption**: We KNOW the exact revenue-per-employee ratio (e.g., from last year's census or industry studies).\n",
    "\n",
    "- **Prediction model**: Revenue = $50,000 × Employees (known beforehand)\n",
    "- **When it works well**: When the known ratio is accurate and stable over time\n",
    "- **When it fails**: When the true relationship has changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference Estimator\n",
    "KNOWN_RATIO = 50000  # Assume we know this from previous studies\n",
    "\n",
    "# Predict revenue for entire population using known ratio\n",
    "predicted_revenue_diff = population['employees'] * KNOWN_RATIO\n",
    "predicted_total_diff = predicted_revenue_diff.sum()\n",
    "\n",
    "# Calculate prediction errors in sample\n",
    "sample['prediction_diff'] = sample['employees'] * KNOWN_RATIO\n",
    "sample['error_diff'] = sample['revenue'] - sample['prediction_diff']\n",
    "\n",
    "# Correction = weighted sum of errors\n",
    "correction_diff = (sample['error_diff'] * sample['weight']).sum()\n",
    "\n",
    "# Final estimate\n",
    "estimate_diff = predicted_total_diff + correction_diff\n",
    "\n",
    "print(f\"=== DIFFERENCE ESTIMATOR ===\")\n",
    "print(f\"Known ratio: ${KNOWN_RATIO:,} per employee\")\n",
    "print(f\"Predicted total: ${predicted_total_diff:,.0f}\")\n",
    "print(f\"Correction from sample: ${correction_diff:,.0f}\")\n",
    "print(f\"Final estimate: ${estimate_diff:,.0f}\")\n",
    "print(f\"Error vs true total: ${estimate_diff - TRUE_TOTAL:,.0f} ({(estimate_diff - TRUE_TOTAL)/TRUE_TOTAL*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 GREG Estimator\n",
    "\n",
    "**Key feature**: LEARNS a linear relationship from the sample data.\n",
    "\n",
    "- **Prediction model**: Revenue = β₀ + β₁ × Employees (coefficients estimated from sample)\n",
    "- **Main advantage**: Robust to model misspecification, achieves calibration\n",
    "- **NSO favorite**: Used in production systems like Statistics Canada's GES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GREG ESTIMATOR ===\n",
      "Learned relationship: Revenue = $38,407 + $39,592 × Employees\n",
      "Predicted total: $403,956,547\n",
      "Correction from sample: $-0\n",
      "Final estimate: $403,956,547\n",
      "Error vs true total: $-75,708,514 (-15.8%)\n"
     ]
    }
   ],
   "source": [
    "# GREG Estimator\n",
    "greg_model = LinearRegression()\n",
    "greg_model.fit(sample[['employees']], sample['revenue'], sample_weight=sample['weight'])\n",
    "\n",
    "# Predict for entire population\n",
    "predicted_revenue_greg = greg_model.predict(population[['employees']])\n",
    "predicted_total_greg = predicted_revenue_greg.sum()\n",
    "\n",
    "# Calculate errors in sample\n",
    "sample['prediction_greg'] = greg_model.predict(sample[['employees']])\n",
    "sample['error_greg'] = sample['revenue'] - sample['prediction_greg']\n",
    "\n",
    "# Correction\n",
    "correction_greg = (sample['error_greg'] * sample['weight']).sum()\n",
    "\n",
    "# Final estimate\n",
    "estimate_greg = predicted_total_greg + correction_greg\n",
    "\n",
    "print(f\"=== GREG ESTIMATOR ===\")\n",
    "print(f\"Learned relationship: Revenue = ${greg_model.intercept_:,.0f} + ${greg_model.coef_[0]:,.0f} × Employees\")\n",
    "print(f\"Predicted total: ${predicted_total_greg:,.0f}\")\n",
    "print(f\"Correction from sample: ${correction_greg:,.0f}\")\n",
    "print(f\"Final estimate: ${estimate_greg:,.0f}\")\n",
    "print(f\"Error vs true total: ${estimate_greg - TRUE_TOTAL:,.0f} ({(estimate_greg - TRUE_TOTAL)/TRUE_TOTAL*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 PPI Estimator (using Machine Learning)\n",
    "\n",
    "**Key innovation**: Can use ANY prediction model, including complex ML algorithms.\n",
    "\n",
    "- **Prediction model**: Random Forest (or any ML model)\n",
    "- **Main advantage**: Can capture complex, non-linear relationships\n",
    "- **Trade-off**: No calibration guarantees, requires careful model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPI Estimator using Random Forest\n",
    "# In practice, this would be trained on a larger labeled dataset\n",
    "ppi_model = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "ppi_model.fit(sample[['employees']], sample['revenue'])\n",
    "\n",
    "# Predict for entire population\n",
    "predicted_revenue_ppi = ppi_model.predict(population[['employees']])\n",
    "predicted_total_ppi = predicted_revenue_ppi.sum()\n",
    "\n",
    "# Calculate errors in sample\n",
    "sample['prediction_ppi'] = ppi_model.predict(sample[['employees']])\n",
    "sample['error_ppi'] = sample['revenue'] - sample['prediction_ppi']\n",
    "\n",
    "# Correction\n",
    "correction_ppi = (sample['error_ppi'] * sample['weight']).sum()\n",
    "\n",
    "# Final estimate\n",
    "estimate_ppi = predicted_total_ppi + correction_ppi\n",
    "\n",
    "print(f\"=== PPI ESTIMATOR ===\")\n",
    "print(f\"Model: Random Forest with {ppi_model.n_estimators} trees\")\n",
    "print(f\"Predicted total: ${predicted_total_ppi:,.0f}\")\n",
    "print(f\"Correction from sample: ${correction_ppi:,.0f}\")\n",
    "print(f\"Final estimate: ${estimate_ppi:,.0f}\")\n",
    "print(f\"Error vs true total: ${estimate_ppi - TRUE_TOTAL:,.0f} ({(estimate_ppi - TRUE_TOTAL)/TRUE_TOTAL*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Visualize the Core Concept\n",
    "\n",
    "This visualization shows how ALL estimators follow the same \"predict-and-correct\" pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization showing predict-and-correct decomposition\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "estimators = ['True Total', 'Difference', 'GREG', 'PPI']\n",
    "predictions = [0, predicted_total_diff, predicted_total_greg, predicted_total_ppi]\n",
    "corrections = [TRUE_TOTAL, correction_diff, correction_greg, correction_ppi]\n",
    "totals = [TRUE_TOTAL, estimate_diff, estimate_greg, estimate_ppi]\n",
    "\n",
    "x = np.arange(len(estimators))\n",
    "width = 0.6\n",
    "\n",
    "# Create stacked bar chart\n",
    "bars1 = ax.bar(x, predictions, width, label='Predicted Total', color='lightblue', edgecolor='black')\n",
    "bars2 = ax.bar(x, corrections, width, bottom=predictions, label='Correction', color='orange', edgecolor='black')\n",
    "\n",
    "# Add total estimate values on top\n",
    "for i, (pred, corr, total) in enumerate(zip(predictions, corrections, totals)):\n",
    "    ax.text(i, total + 50000, f'${total/1e6:.1f}M', ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "    \n",
    "    # Add prediction and correction values inside bars\n",
    "    if i > 0:  # Skip true total\n",
    "        ax.text(i, pred/2, f'${pred/1e6:.1f}M', ha='center', va='center', fontsize=10)\n",
    "        ax.text(i, pred + corr/2, f'${corr/1e6:+.1f}M', ha='center', va='center', fontsize=10)\n",
    "\n",
    "ax.set_ylabel('Revenue ($)', fontsize=12)\n",
    "ax.set_title('The Core Logic of All Survey Estimators\\n' + \n",
    "             'Total Estimate = Predicted Total + Correction for Prediction Error',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(estimators, fontsize=12)\n",
    "ax.legend(fontsize=12, loc='upper right')\n",
    "\n",
    "# Add horizontal line at true total\n",
    "ax.axhline(y=TRUE_TOTAL, color='red', linestyle='--', alpha=0.7, linewidth=2)\n",
    "\n",
    "# Format y-axis to show millions\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1e6:.0f}M'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights Summary\n",
    "\n",
    "### The Universal Formula\n",
    "All estimators follow: **Total Estimate = Predicted Total + Correction**\n",
    "\n",
    "### What Makes Each Estimator Different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "summary_data = {\n",
    "    'Estimator': ['Difference', 'GREG', 'PPI'],\n",
    "    'Prediction Model': ['Known: $50,000/employee', 'Learned: Linear regression', 'Learned: Random Forest'],\n",
    "    'Predicted Total': [f'${predicted_total_diff/1e6:.1f}M', \n",
    "                       f'${predicted_total_greg/1e6:.1f}M', \n",
    "                       f'${predicted_total_ppi/1e6:.1f}M'],\n",
    "    'Correction': [f'${correction_diff/1e6:+.1f}M', \n",
    "                  f'${correction_greg/1e6:+.1f}M', \n",
    "                  f'${correction_ppi/1e6:+.1f}M'],\n",
    "    'Final Estimate': [f'${estimate_diff/1e6:.1f}M', \n",
    "                      f'${estimate_greg/1e6:.1f}M', \n",
    "                      f'${estimate_ppi/1e6:.1f}M'],\n",
    "    'Error': [f'{(estimate_diff - TRUE_TOTAL)/TRUE_TOTAL*100:.1f}%', \n",
    "             f'{(estimate_greg - TRUE_TOTAL)/TRUE_TOTAL*100:.1f}%', \n",
    "             f'{(estimate_ppi - TRUE_TOTAL)/TRUE_TOTAL*100:.1f}%']\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(f\"True Total: ${TRUE_TOTAL/1e6:.1f}M\\n\")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Moving On: Key Questions to Test Your Understanding\n",
    "\n",
    "1. **Why do we need the correction term?**\n",
    "   - Because our prediction model is never perfect. The correction ensures unbiasedness.\n",
    "\n",
    "2. **What happens if we skip the correction?**\n",
    "   - We get a biased estimate. Even with a great model, small systematic errors accumulate over the population.\n",
    "\n",
    "3. **When would the Difference Estimator be best?**\n",
    "   - When you have reliable external information about the true relationship (e.g., last year's census).\n",
    "\n",
    "4. **Why do NSOs love GREG?**\n",
    "   - It's robust (works even if model is wrong) and achieves calibration (sample totals match known population totals).\n",
    "\n",
    "5. **What's the main advantage of PPI?**\n",
    "   - Can use powerful ML models for better predictions, potentially achieving much lower variance.\n",
    "\n",
    "6. **What's the main limitation of PPI?**\n",
    "   - No calibration guarantees. Different ML model needed for each variable. Less transparent for official statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you understand the core \"predict-and-correct\" logic, you can explore:\n",
    "\n",
    "1. **Model-Calibrated Estimators**: How they generalize GREG to non-linear models while keeping calibration\n",
    "2. **Variance estimation**: How each estimator's variance depends on model quality\n",
    "3. **Multi-purpose surveys**: Why calibration matters when estimating many variables\n",
    "4. **CrossPPI**: How to avoid overfitting when using the same data for training and correction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
