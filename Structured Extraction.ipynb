{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a55478f5-cdb7-47e7-b274-1e953530b660",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "LLMs can generate text that can veer off-topic or contain fabricated details. This unpredictability poses a serious challenge for organizations that need to distill consistent, structured data (e.g., addresses, invoices, summaries) from large volumes of unstructured text. When most people talk about \"AI\" (like ChatGPT) they picture them generating free-form text that can range from a coherent explanation to a complete tangent.\n",
    "\n",
    "\n",
    "This often makes LLMs too unpredictable and unreliable for real-world tasks, especially in enterprise or mission-critical settings. These criticisms are completely valid since LLMs are probabilistic, generative systems prone to variability. Traditional unstructured text output is hard to trust if the LLM “hallucinates” or drift off-topic.\n",
    "\n",
    "\n",
    "**Structured extraction** is an approach that helps partially mitigate these concerns.\n",
    "\n",
    "Instead of requesting open-ended text, we give the model a **blueprint** (a strictly defined schema and demand the output adhere to it). We specify *exactly how we want the model’s output to look*—in this case, structured data in JSON. Then, we use **Pydantic** (a Python library) to formally define and validate that output by enforcing type definitions and validates JSON data\n",
    "\n",
    "This constrained use of AI addresses one of the biggest concerns: **unpredictability**. By requiring the model to produce output that follows a strict schema, any errors become more detectable, and the output can be systematically processed. Structured extraction places a guardrail around the model:\n",
    "\n",
    "\n",
    "1. Define a schema describing exactly what fields and data types are expected.\n",
    "2. Instruct the LLM to return JSON conforming to that schema.\n",
    "2. If the LLM returns something that doesn’t match the schema, we can immediately detect the error and handle it (e.g., ask the model again, or flag the output).\n",
    "\n",
    "\n",
    "\n",
    "This approach reduces the “black-box” feeling of AI text generation, making outputs more transparent, testable, and suitable for downstream workflows. By constraining the model’s responses to a known structure, we transform what might otherwise be a black-box AI process into a predictable and testable system—precisely the kind of safeguard critics demand.\n",
    "\n",
    "Below, we illustrate how to implement structured extraction in practice, using code samples to demonstrate each step of guiding an LLM to produce verifiable JSON responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4614e2b8-30f1-4d08-8ab5-c27a7cf37c11",
   "metadata": {},
   "source": [
    "## How Structured Extraction Works \n",
    "\n",
    "Before demonstrating how to guide a Large Language Model (LLM) toward a strict schema, it’s instructive to see what happens without any constraints. In the following example, we simply prompt the model about Canada, only limiting the number of tokens (for brevity) rather than specifying any structured output.\n",
    "\n",
    "Here we're just using the Ollama library and using the LLaMA 3.18b model, running it locally on our machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c03a3004-85ae-4401-9ae2-1bfa61803436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Canada! The Great White North is a vast and beautiful country located in '\n",
      " \"North America, sharing the world's longest international border with the \"\n",
      " 'United States to the south. Here are some interesting facts about Canada:\\n'\n",
      " '\\n'\n",
      " '**Geography**\\n'\n",
      " '\\n'\n",
      " 'Canada is a large country, covering an area of approximately 10 million '\n",
      " 'square kilometers (3.9 million sq mi). It has a diverse geography, featuring '\n",
      " 'mountains (including the Canadian Rockies), forests, lakes, rivers, and '\n",
      " 'coastlines along the Atlantic, Pacific, and Arctic Oceans. The country can '\n",
      " 'be divided into several regions: Western Canada, including British Columbia '\n",
      " 'and Alberta; Central Canada, comprising provinces like Ontario and Quebec; '\n",
      " 'and Eastern Canada, which includes provinces like Nova Scotia and New '\n",
      " 'Brunswick.\\n'\n",
      " '\\n'\n",
      " '**Cities**\\n'\n",
      " '\\n'\n",
      " 'Some of Canada')\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from pprint import pprint as pp\n",
    "\n",
    "response = chat(\n",
    "  messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': 'Tell me about Canada.',\n",
    "    }\n",
    "  ],\n",
    "  model='llama3.1',\n",
    "  options={'num_predict': 150} # Maximum number of tokens to predict when generating text\n",
    ")\n",
    "pp(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d7e706-dcdc-4be2-bbcd-1f02f8d4e584",
   "metadata": {},
   "source": [
    "As expected, the output is an unstructured descriptive paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc90a7f-c648-49a9-a60b-041c96f6f963",
   "metadata": {},
   "source": [
    "\n",
    "### From Free-Form to Structured\n",
    "\n",
    "Now we build on existing code examples to illustrate how an LLM can be guided to output structured ouput according to a schema. To replace this open-ended style with a structured extraction approach, we’ll use Pydantic to define a schema (i.e., which fields we expect and in what format) and then instruct the LLM to output only valid JSON matching that schema.\n",
    "#### Defining a Pydantic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df984dd-8f70-424f-bbfe-1b1a31e82cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Country(BaseModel):\n",
    "  name: str\n",
    "  capital: str\n",
    "  languages: list[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fc4de9-e7c7-4cab-9c82-bae328024036",
   "metadata": {},
   "source": [
    "Pydantic will automatically generate a JSON Schema to describe the fields. This schema will look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "741f50b5-8c7c-48c5-b478-af6d3625014c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "  'capital': {'title': 'Capital', 'type': 'string'},\n",
       "  'languages': {'items': {'type': 'string'},\n",
       "   'title': 'Languages',\n",
       "   'type': 'array'}},\n",
       " 'required': ['name', 'capital', 'languages'],\n",
       " 'title': 'Country',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Country.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1043a5-f882-4ac5-9dd6-03cff9fa8a4e",
   "metadata": {},
   "source": [
    "###  Sending the Schema to the LLM\n",
    "\n",
    "When we call the LLM, we include this JSON schema in the request so that the model knows **what** to return and **how** to format it. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e2748df-5f95-493b-a1f6-fc3760770906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "\n",
    "response = chat(\n",
    "  messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': 'Tell me about Canada.',\n",
    "    }\n",
    "  ],\n",
    "  model='llama3.1',\n",
    "  format=Country.model_json_schema(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e8292-d2da-4a7f-a1dc-799e80ed892f",
   "metadata": {},
   "source": [
    "This tells the model: “Return your answer as valid JSON that matches the schema for Country.” Instead of a free-form reply, the model is instructed to produce something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c15c5c2-b3f9-4103-ad56-de7d98a6a33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{ \"name\" : \"Canada\", \"capital\" : \"Ottawa\", \"languages\" : [\"English\", \"French\"] }'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ba7d1f-ab64-40ef-9a52-3cb7b32c603a",
   "metadata": {},
   "source": [
    "### Validating the Output\n",
    "Once the model responds, we validate the JSON to confirm it meets the schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03d9bd44-abc2-49e3-9c00-0e31f22d4313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Canada' capital='Ottawa' languages=['English', 'French']\n"
     ]
    }
   ],
   "source": [
    "country = Country.model_validate_json(response.message.content)\n",
    "print(country)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10780a9-78aa-4d43-8f53-adff752eb002",
   "metadata": {},
   "source": [
    "If the output fails to match the schema (for example, the LLM omits the languages field), Pydantic raises an error. This immediate feedback loop is crucial for reliability. **We’re not simply trusting the AI to always comply; we’re enforcing compliance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e506b36-442c-425b-809f-b64bf4ffe794",
   "metadata": {},
   "source": [
    "## Concrete Example: Addresses\n",
    "Here’s a more realistic use case: parsing physical addresses from a piece of text. We define two Pydantic models, Address and Addresses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ef9106e-3c0f-4e1e-b14f-a9806aa84320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Address(BaseModel):\n",
    "    name: str\n",
    "    street_number: str\n",
    "    street_name: str\n",
    "    city: str\n",
    "\n",
    "class Addresses(BaseModel):\n",
    "    addresses: list[Address]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e696e5f-54a2-44f1-bb93-1e77a4d4a01a",
   "metadata": {},
   "source": [
    "Let’s imagine the user has a piece of text describing several locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c53373b4-78fa-4089-9ce9-ece77f4aa8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  \"\"\"\n",
    "The Ottawa Public Library is at 150 Elgin Street, Ottawa.\n",
    "Down the street, Sarah Wilson runs her bakery at 240 Laurier Avenue, Ottawa.\n",
    "Over in Kanata, Tech Corp's office is at 1385 Terry Fox Drive.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2651a6-54fc-4a65-82be-8c58492fd8ab",
   "metadata": {},
   "source": [
    "We pass these messages to the LLM. The Llama 3.1 model processes the input messages and generates a response that adheres to the specified JSON schema. It uses the context from the system message to understand its role as a data parsing assistant and formats the extracted information according to the provided schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30352f21-5c9d-44cd-b2b5-9d35b7f36c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a data parsing assistant. \n",
    "User provides unstructued data containing addresses. \n",
    "Your goal is to output it as JSON.\n",
    "\"\"\"\n",
    "response = chat(\n",
    "    model='llama3.1:8b',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": data}\n",
    "    ],\n",
    "    format=Addresses.model_json_schema(),  # Use Pydantic to generate the schema or format=schema\n",
    "    options={'temperature': 0},  # Make responses deterministic\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be548585-d670-4bf8-91f4-68cef4b84139",
   "metadata": {},
   "source": [
    "This is the raw output from the model now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beb3f756-c52f-4c9e-bd04-898367f2f436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('{\\n'\n",
      " '  \"addresses\": [\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"Ottawa Public Library\",\\n'\n",
      " '      \"street_number\": \"150\",\\n'\n",
      " '      \"street_name\": \"Elgin Street\",\\n'\n",
      " '      \"city\": \"Ottawa\"\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"Sarah Wilson\\'s Bakery\",\\n'\n",
      " '      \"street_number\": \"240\",\\n'\n",
      " '      \"street_name\": \"Laurier Avenue\",\\n'\n",
      " '      \"city\": \"Ottawa\"\\n'\n",
      " '    },\\n'\n",
      " '    {\\n'\n",
      " '      \"name\": \"Tech Corp Office\",\\n'\n",
      " '      \"street_number\": \"1385\",\\n'\n",
      " '      \"street_name\": \"Terry Fox Drive\",\\n'\n",
      " '      \"city\": \"Kanata\"\\n'\n",
      " '    }\\n'\n",
      " '  ]\\n'\n",
      " '}')\n"
     ]
    }
   ],
   "source": [
    "pp(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd22aa7f-f258-4595-924d-c8d0b0be5d54",
   "metadata": {},
   "source": [
    "After validating the JSON against our Addresses model, we can convert it into a pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3e9a789-66ba-49bb-9c7d-60817d201a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addresses(addresses=[Address(name='Ottawa Public Library', street_number='150', street_name='Elgin Street', city='Ottawa'), Address(name=\"Sarah Wilson's Bakery\", street_number='240', street_name='Laurier Avenue', city='Ottawa'), Address(name='Tech Corp Office', street_number='1385', street_name='Terry Fox Drive', city='Kanata')])\n"
     ]
    }
   ],
   "source": [
    "# Use Pydantic to validate the response\n",
    "address_ouput = Addresses.model_validate_json(response.message.content)\n",
    "pp(address_ouput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08415d45-bd11-4e35-8f30-cd80b635d9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>street_number</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ottawa Public Library</td>\n",
       "      <td>150</td>\n",
       "      <td>Elgin Street</td>\n",
       "      <td>Ottawa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sarah Wilson's Bakery</td>\n",
       "      <td>240</td>\n",
       "      <td>Laurier Avenue</td>\n",
       "      <td>Ottawa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tech Corp Office</td>\n",
       "      <td>1385</td>\n",
       "      <td>Terry Fox Drive</td>\n",
       "      <td>Kanata</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name street_number      street_name    city\n",
       "0  Ottawa Public Library           150     Elgin Street  Ottawa\n",
       "1  Sarah Wilson's Bakery           240   Laurier Avenue  Ottawa\n",
       "2       Tech Corp Office          1385  Terry Fox Drive  Kanata"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def locations_to_df(addresses: Addresses) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert locations Pydantic model to pandas DataFrame.\n",
    "    Each row represents one location with all its fields.\n",
    "    \"\"\"\n",
    "    # Convert each BusinessLocation to a dict and create DataFrame\n",
    "    return pd.DataFrame([loc.model_dump() for loc in addresses.addresses])\n",
    "# Assuming we have our parsed response in parsed_locations\n",
    "df = locations_to_df(address_ouput)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c90463-feb6-4363-865f-b9e4f5a2bac3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "LLMs support structured outputs making it possible to constrain a model's output to a specific format defined by JSON schema. \n",
    "**Structured extraction** is a process that transforms **unstructured text** into a **structured format**, such as JSON, making it easily accessible for further processing, analysis, or storage. \n",
    "\n",
    "Structured outputs have many use cases includuing: \n",
    "1. Parsing data from documents\n",
    "2. Extracting data from images\n",
    "3. Structuring all language model responses\n",
    "\n",
    "With the rise of LLMs, this task can now be accomplished efficiently and affordably, enabling enterprises to unlock valuable insights from large volumes of unstructured data, including PDFs, text files, and scanned documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9752380a-19c3-4989-abdf-00b8e5208610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "    {\n",
      "        \"name\": \"Ottawa Public Library\",\n",
      "        \"address\": \"150 Elgin Street\",\n",
      "        \"city\": \"Ottawa\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Sarah Wilson's Bakery\",\n",
      "        \"address\": \"240 Laurier Avenue\",\n",
      "        \"city\": \"Ottawa\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Tech Corp's office\",\n",
      "        \"address\": \"1385 Terry Fox Drive\",\n",
      "        \"city\": \"Kanata\"\n",
      "    }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from openai.types.chat import ChatCompletion  \n",
    "\n",
    "\n",
    "def eval(prompt: str, message: str, model: str = \"gpt-4o\") -> ChatCompletion:\n",
    "    client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "\n",
    "    return client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "res = eval(prompt=prompt, message=data)\n",
    "json_data = res.choices[0].message.content\n",
    "\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071ae70c-42b5-44b1-a24c-486567fdd6ec",
   "metadata": {},
   "source": [
    "We can see that the model didn't return JSON, it returned markdown formated string containing JSON. The reason is that we didn't enable structured output in the API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edcd677a-69b4-4182-beed-bdbecf0a9549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"addresses\": [\n",
      "    {\n",
      "      \"name\": \"Ottawa Public Library\",\n",
      "      \"address\": \"150 Elgin Street\",\n",
      "      \"city\": \"Ottawa\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Sarah Wilson's Bakery\",\n",
      "      \"address\": \"240 Laurier Avenue\",\n",
      "      \"city\": \"Ottawa\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Tech Corp\",\n",
      "      \"address\": \"1385 Terry Fox Drive\",\n",
      "      \"city\": \"Kanata\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def eval(prompt: str, message: str, model: str = \"gpt-4o\") -> ChatCompletion:\n",
    "    client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "\n",
    "    return client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        # Enable strctured output\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "prompt = \"\"\"\n",
    "You are a data parsing assistant. \n",
    "User provides unstructued data containing addresses. \n",
    "Your goal is to output it as JSON.\n",
    "\"\"\"\n",
    "data =  \"\"\"\n",
    "The Ottawa Public Library is at 150 Elgin Street, Ottawa.\n",
    "Down the street, Sarah Wilson runs her bakery at 240 Laurier Avenue, Ottawa.\n",
    "Over in Kanata, Tech Corp's office is at 1385 Terry Fox Drive.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "res = eval(prompt=prompt, message=data)\n",
    "json_data = res.choices[0].message.content\n",
    "\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788e3e20-1d61-43ca-ae94-c11f72668423",
   "metadata": {},
   "source": [
    "Now, running the same code returns plain JSON. This is not only great because we don't need to parse anything extra but, but it also guarantees that the LLM won't include any free-from text such as \"Sure, here is your data!{}\"\n",
    "\n",
    "\n",
    "**The problem is, we don't have the data shaped defined; lets call it *schema*. Our schema is now up to the LLM, and it might change based on user input**. Lets reformat the data to see it in action. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6be852a-6681-4c3e-af33-c7f4cdd0e6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"results\": [\n",
      "        {\n",
      "            \"name\": \"Ottawa Public Library\",\n",
      "            \"branch\": \"Main Branch\",\n",
      "            \"address\": {\n",
      "                \"street\": \"150 Elgin Street\",\n",
      "                \"city\": \"Ottawa\",\n",
      "                \"postal_code\": \"K1P 1L7\"\n",
      "            },\n",
      "            \"contact\": {\n",
      "                \"email\": \"library@ottawa.ca\",\n",
      "                \"website\": \"https://biblioottawalibrary.ca\"\n",
      "            },\n",
      "            \"status\": \"Open Now\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Sarah's Bakery & Café\",\n",
      "            \"address\": {\n",
      "                \"line_1\": \"240 Laurier Avenue\",\n",
      "                \"city\": \"Ottawa\",\n",
      "                \"postal_code\": \"K1P 5J7\"\n",
      "            },\n",
      "            \"contact\": {\n",
      "                \"email\": \"sarah@sarahsbakery.ca\",\n",
      "                \"website\": \"www.sarahsbakery.ca\"\n",
      "            },\n",
      "            \"rating\": \"4.8\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"TECH CORP GLOBAL\",\n",
      "            \"address\": {\n",
      "                \"street\": \"1385 Terry Fox Drive\",\n",
      "                \"city\": \"Kanata\",\n",
      "                \"province\": \"Ontario\",\n",
      "                \"postal_code\": \"K2K 3K2\"\n",
      "            },\n",
      "            \"contact\": {\n",
      "                \"email\": \"info@techcorp.com\",\n",
      "                \"website\": \"www.techcorp.com/contact\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Messy web-scraped format with typical HTML artifacts and inconsistent formatting\n",
    "data_2 = \"\"\"\n",
    "[Search Results]\n",
    "* Ottawa Public Library *\n",
    "Contact Us > Main Branch\n",
    "Located at: &nbsp;150 Elgin Street, Ottawa\n",
    "Status: OPEN NOW! 📚\n",
    "Customer Service: library@ottawa.ca\n",
    "Visit us online: https://biblioottawalibrary.ca\n",
    "Postal: K1P 1L7\n",
    "---------------------\n",
    "<div class=\"business-listing\">\n",
    "Sarah's Bakery & Café [⭐️4.8]\n",
    "Address line 1: 240 \n",
    "Address line 2: Laurier Avenue\n",
    "City: Ottawa\n",
    "Postal Code: K1P 5J7\n",
    "Contact: sarah@sarahsbakery.ca\n",
    "www.sarahsbakery.ca\n",
    "</div>\n",
    "...Read More...\n",
    "---------------------\n",
    "TECH CORP GLOBAL\n",
    "www.techcorp.com/contact\n",
    "📍 1385 Terry Fox Drive\n",
    "Kanata, Ontario\n",
    "[Click to view map]\n",
    "Email: info@techcorp.com\n",
    "Postal: K2K 3K2\n",
    "\"\"\"\n",
    "\n",
    "res = eval(prompt=prompt, message=data_2)\n",
    "json_data = res.choices[0].message.content\n",
    "\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e17bb8-4c79-473c-adc7-0ea90d4ebf74",
   "metadata": {},
   "source": [
    "## Enforcing a Strict Schema (Pydantic Example)\n",
    "Usually, JSON ouput won't cut it in software systems. Its just a string after all. We have to ensure that the LLM indeed returns correctly formed data. \n",
    "\n",
    "To robustly handle data after extracting it, you often need a well-defined schema. Tools like pydantic are excellent for validating that the JSON from the LLM matches the expected structure.\n",
    "  - **BaseModel**: Pydantic's base class that enables data validation\n",
    "   - **Optional**: From Python's typing module, marks fields that aren't required\n",
    "   - **EmailStr**: Pydantic's email validator, ensures valid email format\n",
    "   - **HttpUrl**: Pydantic's URL validator, ensures valid website format\n",
    "   \n",
    "   This model will:\n",
    "   1. Ensure required fields (name, street info, city) are present\n",
    "   2. Allow optional fields to be missing\n",
    "   3. Validate email format if provided\n",
    "   4. Validate URL format if provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e9548ee-51dc-4501-ab20-77df9284ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, EmailStr, HttpUrl\n",
    "from typing import Optional\n",
    "\n",
    "class BusinessLocation(BaseModel):\n",
    "    name: str\n",
    "    street_number: str\n",
    "    street_name: str\n",
    "    city: str\n",
    "    postal_code: Optional[str] = None\n",
    "    email: Optional[EmailStr] = None\n",
    "    website: Optional[HttpUrl] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56e5ab8b-49d4-4a29-a459-0026b69c30b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(prompt: str, message: str, model: str = \"gpt-4o\", model) -> ChatCompletion:\n",
    "    client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "\n",
    "    return client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        # Enable strctured output\n",
    "        response_format=model,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5eaa2e-f050-4852-9c51-329520cdda49",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = eval(prompt=prompt, message=data_2, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc71c211-f161-40f8-b23d-70fdcf6990ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pydantic import BaseModel, constr\n",
    "\n",
    "class Business(BaseModel):\n",
    "    id: int\n",
    "    business_name: str = 'Unregistered Business'\n",
    "    registration_ts: datetime | None\n",
    "    business_number: constr(pattern=r'^\\d{9}$')  # 9-digit pattern\n",
    "    naics_code: constr(pattern=r'^\\d{6}$')       # 6-digit pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a79df5b-889c-4a02-b0dc-61c884292d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 123, 'business_name': 'Hanan Ather Pharmacy', 'registration_ts': datetime.datetime(2023, 1, 15, 9, 30), 'business_number': '123456789', 'naics_code': '446110'}\n"
     ]
    }
   ],
   "source": [
    "external_data = {\n",
    "    'id': 123,\n",
    "    'business_name': 'Hanan Ather Pharmacy',\n",
    "    'registration_ts': '2023-01-15 09:30',\n",
    "    'business_number': '123456789',\n",
    "    'naics_code': '446110'  # Actual NAICS code for pharmacies\n",
    "}\n",
    "\n",
    "business = Business(**external_data)\n",
    "pp(business.model_dump())  # Convert the model to a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23d1b59-8887-48c9-ad91-85af663b6f7e",
   "metadata": {},
   "source": [
    "If the LLM ever returns incorrectly shaped data (e.g., the `id` is missing or the `business_number` is only 8 digits), a `ValidationError` will be raised. This helps ensure you don’t inadvertently store invalid or incomplete data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25570a6a-06ec-4db0-a727-4960ec8f6c08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
