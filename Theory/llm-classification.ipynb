{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76e0d8a7-9bbc-4450-814c-9618f399020a",
   "metadata": {},
   "source": [
    "# Zero-Shot Classification\n",
    "Zero-shot text classification is a task in natural language processing where a model is trained on a set of labeled examples but is then able to classify new examples from previously unseen classes.\n",
    "\n",
    "Zero Shot Classification is the task of predicting a class that wasn't seen by the model during training. This method, which leverages a pre-trained language model, can be thought of as an instance of transfer learning which generally refers to using a model trained for one task in a different application than what it was originally trained for. This is particularly useful for situations where the amount of labeled data is small.\n",
    "\n",
    "In zero shot classification, we provide the model with a prompt and a sequence of text that describes what we want our model to do, in natural language. Zero-shot classification excludes any examples of the desired task being completed. This differs from single or few-shot classification, as these tasks include a single or a few examples of the selected task.\n",
    "\n",
    "\n",
    "Zero, single and few-shot classification seem to be an emergent feature of large language models. This feature seems to come about around model sizes of +100M parameters. The effectiveness of a model at a zero, single or few-shot task seems to scale with model size, meaning that larger models (models with more trainable parameters or layers) generally do better at this task.\n",
    "\n",
    "\n",
    "### Classification as a cloze task\n",
    "One in-the-works approach to keep your eye on is a preprint on Pattern-Exploiting Training (PET) from Schick et al. (2020). In this paper, the authors reformulate text classification as a cloze task.\n",
    "A cloze question considers a sequence which is partially masked and requires predicting the missing value(s) from the context. PET requires a human practitioner to construct several task-appropriate cloze-style templates which, in the case of topic classification, could look something like the following:\n",
    "A pre-trained masked language model is then tasked with choosing the most likely value for the masked (blank) word from among the possible class names for each cloze sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bddf30f8-c05a-4c5d-87f2-a87389aafb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (0.26.1)\n",
      "Requirement already satisfied: jellyfish in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (1.1.3)\n",
      "Requirement already satisfied: Levenshtein==0.26.1 in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (from python-Levenshtein) (0.26.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /Users/hananather/Desktop/LLM-notes/venv/lib/python3.13/site-packages (from Levenshtein==0.26.1->python-Levenshtein) (3.12.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset A</th>\n",
       "      <th>Dataset B</th>\n",
       "      <th>Levenshtein Score</th>\n",
       "      <th>Jaro-Winkler Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GC</td>\n",
       "      <td>Government of Canada</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RCMP</td>\n",
       "      <td>Royal Canadian Mounted Police</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.617816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CRA</td>\n",
       "      <td>Canada Revenue Agency</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.587302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RCM</td>\n",
       "      <td>Royal Canadian Mint</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.590643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RCMP</td>\n",
       "      <td>RCM</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.941667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset A                      Dataset B  Levenshtein Score  \\\n",
       "0        GC           Government of Canada           0.181818   \n",
       "1      RCMP  Royal Canadian Mounted Police           0.242424   \n",
       "2       CRA          Canada Revenue Agency           0.250000   \n",
       "3       RCM            Royal Canadian Mint           0.272727   \n",
       "4      RCMP                            RCM           0.857143   \n",
       "\n",
       "   Jaro-Winkler Score  \n",
       "0            0.516667  \n",
       "1            0.617816  \n",
       "2            0.587302  \n",
       "3            0.590643  \n",
       "4            0.941667  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install python-Levenshtein jellyfish\n",
    "\n",
    "# Reattempting execution after installation\n",
    "import Levenshtein\n",
    "import jellyfish\n",
    "import pandas as pd\n",
    "\n",
    "# Define dataset with Canadian government agencies\n",
    "dataset = [\n",
    "    (\"GC\", \"Government of Canada\"),\n",
    "    (\"RCMP\", \"Royal Canadian Mounted Police\"),\n",
    "    (\"CRA\", \"Canada Revenue Agency\"),\n",
    "    (\"RCM\", \"Royal Canadian Mint\"),\n",
    "    (\"RCMP\", \"RCM\"),\n",
    "]\n",
    "\n",
    "# Compute Levenshtein and Jaro-Winkler scores\n",
    "# Compute Levenshtein and Jaro-Winkler scores\n",
    "results = []\n",
    "for a, b in dataset:\n",
    "    levenshtein_score = Levenshtein.ratio(a, b)\n",
    "    jaro_winkler_score = jellyfish.jaro_winkler_similarity(a, b)  # Correct function\n",
    "\n",
    "    results.append((a, b, levenshtein_score, jaro_winkler_score))\n",
    "\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(results, columns=[\"Dataset A\", \"Dataset B\", \"Levenshtein Score\", \"Jaro-Winkler Score\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7623e5b6-467b-4cd7-ab5f-c3a5ecbf8833",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce7d4bf-9c8c-4eca-978e-50553f70a094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
