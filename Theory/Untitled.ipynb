{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d55ece7c-1b2e-4fb8-bc36-14d1f0e653db",
   "metadata": {},
   "source": [
    "A prompt is an instruction given to a model to perform a task. A prompt generally consists of one or more of the following parts:\n",
    "- Task description: \n",
    "- Examples(s) of how to do this task:\n",
    "- The task:\n",
    "\n",
    "For prompting to work, the model has to be able to follow instructions. If a model is bad at it, it doesn't matter how good your prompt is, the model won't be able to follow it. \n",
    "\n",
    "How much prompt engineering is needed depends on how robust the model is to prompt perturbation.\n",
    "You can measure a model's robustness by randomly perturbing the prompts to see how the output changes. \n",
    "- just like instuction following capability, a model's robustness is strongly correlated with overall capability. As models become stronger, they also become more robust. For this reason, working with stronger models can often save you headaches and reduce time wasted on fiddling.\n",
    "\n",
    "## In-Context Learning: Zero-Shot and Few-Shot Prompting\n",
    "Traditionally a model learns the desirable behaviour during training (pre-training, post-training, finetuning) which involves updating the models weights. The GPT-3 paper demonstrated that language models can learn the desirable behavior from examples in the prompt, even if this desirable behaviour is different from what the model was originally trained to do. \n",
    "\n",
    "Each example provided in the prompt is called a shot.\n",
    "Exactly how many examples are needed depends on the model and the application. You need to experiment to determine the number of examples for your application. In general, the more examples we show the model, the better it can learn. The number of examples is limited by the model's maximum context length. The more examples there are, the longer our prompt will be, increasing inference cost. \n",
    "\n",
    "> as models become more powerful, they become better at understanding and following instructions, which leads to better performance with fewer examples\n",
    "\n",
    "Fran√ßois Chollet compared a foundation model to a library of many different programs. Each program can be activated by certain prompts. In this view, prompt engineering is about finding the right prompt that can activate the program you want. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
